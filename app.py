import streamlit as st
import requests
from datetime import datetime
import json
import pandas as pd
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ìƒìˆ˜ ì •ì˜
MAX_MESSAGES = 50
API_TIMEOUT = 30
API_URL = "https://model.odyssey-ai.svc.cluster.local/v1/completions"

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        max-width: 80%;
    }
    .user-message {
        background-color: #e3f2fd;
        margin-left: 20%;
    }
    .assistant-message {
        background-color: #f5f5f5;
        margin-right: 20%;
    }
    .message-timestamp {
        color: #666;
        font-size: 0.8rem;
    }
    .error-message {
        color: #f44336;
        background-color: #ffebee;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'messages' not in st.session_state:
        st.session_state['messages'] = []
    if 'error_count' not in st.session_state:
        st.session_state['error_count'] = 0
    if 'last_timestamps' not in st.session_state:
        st.session_state['last_timestamps'] = []

def call_llm_api(prompt, temperature=0.7, max_tokens=512):
    """LLM API í˜¸ì¶œ í•¨ìˆ˜"""
    try:
        response = requests.post(
            API_URL,
            json={
                "model": "model",
                "prompt": prompt,
                "max_tokens": max_tokens,
                "temperature": temperature,
                "top_p": 0.95,
                "frequency_penalty": 0.0,
                "presence_penalty": 0.0,
            },
            verify=False,
            timeout=API_TIMEOUT
        )
        response.raise_for_status()
        return response.json()["choices"][0]["text"].strip(), None
    except requests.Timeout:
        return None, "ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
    except requests.RequestException as e:
        return None, f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    except (KeyError, IndexError, json.JSONDecodeError) as e:
        return None, f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def add_message(role, content):
    """ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state['messages'].append({
        "role": role,
        "content": content,
        "timestamp": timestamp
    })
    
    # ë©”ì‹œì§€ ìˆ˜ ì œí•œ
    if len(st.session_state['messages']) > MAX_MESSAGES:
        st.session_state['messages'] = st.session_state['messages'][-MAX_MESSAGES:]

def export_chat_history():
    """ëŒ€í™” ë‚´ì—­ ë‚´ë³´ë‚´ê¸°"""
    if not st.session_state['messages']:
        st.sidebar.warning("ë‚´ë³´ë‚¼ ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    df = pd.DataFrame(st.session_state['messages'])
    csv = df.to_csv(index=False)
    st.sidebar.download_button(
        label="ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ (CSV)",
        data=csv,
        file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )

def display_chat_messages():
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    for msg in st.session_state['messages']:
        message_container = st.container()
        with message_container:
            if msg["role"] == "user":
                st.markdown(f"""
                    <div class="chat-message user-message">
                        {msg["content"]}
                        <div class="message-timestamp">{msg["timestamp"]}</div>
                    </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                    <div class="chat-message assistant-message">
                        {msg["content"]}
                        <div class="message-timestamp">{msg["timestamp"]}</div>
                    </div>
                """, unsafe_allow_html=True)

def main():
    # ì„¸ì…˜ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ì„¤ì •")
    temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7)
    max_tokens = st.sidebar.slider("Max Tokens", 50, 1000, 512)
    
    if st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state['messages'] = []
        st.session_state['error_count'] = 0
        st.rerun()
    
    # ëŒ€í™” ë‚´ì—­ ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
    export_chat_history()
    
    # ë©”ì¸ í™”ë©´
    st.title("AI ì±—ë´‡ ğŸ¤–")
    
    # ì±„íŒ… ì´ë ¥ í‘œì‹œ
    display_chat_messages()
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        add_message("user", prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.spinner("AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response, error = call_llm_api(prompt, temperature, max_tokens)
            
            if error:
                st.session_state['error_count'] += 1
                st.error(error)
                if st.session_state['error_count'] >= 3:
                    st.warning("ì—¬ëŸ¬ ë²ˆì˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    time.sleep(5)
            else:
                st.session_state['error_count'] = 0
                add_message("assistant", response)
                st.rerun()

if __name__ == "__main__":
    main()
